{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) https://www.tensorflow.org/guide/eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and format the mnist data\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
    "   tf.cast(mnist_labels,tf.int64)))\n",
    "dataset = dataset.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "mnist_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
    "                         input_shape=(None, None, 1)),\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:  [[ 0.01383554 -0.04311896  0.00468579  0.02663172 -0.05253503 -0.01703398\n",
      "   0.0023439  -0.01505692  0.01761053 -0.02049292]]\n"
     ]
    }
   ],
   "source": [
    "for images,labels in dataset.take(1):\n",
    "      print(\"Logits: \", mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:  [[ 0.01131738 -0.0349133   0.00436365  0.02141805 -0.04255836 -0.01222132\n",
      "   0.00522296 -0.01136101  0.0135953  -0.01777178]]\n",
      "Logits:  [[ 0.00868497 -0.02633667  0.00378692  0.01505686 -0.03012795 -0.00988068\n",
      "   0.00062857 -0.00875417  0.01069043 -0.0108057 ]]\n"
     ]
    }
   ],
   "source": [
    "for images,labels in dataset.take(2):\n",
    "      print(\"Logits: \", mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:  [[ 0.01672072 -0.0496078   0.005604    0.02883614 -0.06121216 -0.01935804\n",
      "   0.00452593 -0.01870145  0.01982135 -0.02325529]]\n",
      "Logits:  [[ 0.01234549 -0.03548413  0.00298782  0.02152538 -0.04342612 -0.01452789\n",
      "   0.00280155 -0.01149965  0.01273404 -0.01511956]]\n",
      "Logits:  [[ 0.01762662 -0.04036514  0.00041118  0.0266051  -0.05514634 -0.01811177\n",
      "   0.00573437 -0.01516054  0.01509123 -0.01738932]]\n"
     ]
    }
   ],
   "source": [
    "for images,labels in dataset.take(3):\n",
    "      print(\"Logits: \", mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = mnist_model(images, training=True)\n",
    "\n",
    "        # Add asserts to check the shape of the output.\n",
    "        tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "\n",
    "        loss_value = loss_object(labels, logits)\n",
    "    \n",
    "    print('loss_value=',loss_value.numpy())\n",
    "\n",
    "    loss_history.append(loss_value.numpy())  #.mean() #It is already reduced mean by the loss function\n",
    "    print('loss_history=',loss_history)\n",
    "    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for (batch, (images, labels)) in enumerate(dataset):\n",
    "            print('batch', batch)\n",
    "            print('images shape:', images.shape)\n",
    "            print('labels shape:', labels.shape)\n",
    "            train_step(images, labels)\n",
    "        print ('Epoch {} finished'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2914927\n",
      "loss_history= [2.2914927]\n",
      "batch 1\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2886176\n",
      "loss_history= [2.2914927, 2.2886176]\n",
      "batch 2\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2649162\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162]\n",
      "batch 3\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2948909\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909]\n",
      "batch 4\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2760973\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973]\n",
      "batch 5\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2876854\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973, 2.2876854]\n",
      "batch 6\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2797115\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973, 2.2876854, 2.2797115]\n",
      "batch 7\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.301657\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973, 2.2876854, 2.2797115, 2.301657]\n",
      "batch 8\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2899017\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973, 2.2876854, 2.2797115, 2.301657, 2.2899017]\n",
      "batch 9\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2715375\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973, 2.2876854, 2.2797115, 2.301657, 2.2899017, 2.2715375]\n",
      "batch 10\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.2887452\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973, 2.2876854, 2.2797115, 2.301657, 2.2899017, 2.2715375, 2.2887452]\n",
      "batch 11\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n",
      "loss_value= 2.298511\n",
      "loss_history= [2.2914927, 2.2886176, 2.2649162, 2.2948909, 2.2760973, 2.2876854, 2.2797115, 2.301657, 2.2899017, 2.2715375, 2.2887452, 2.298511]\n",
      "batch 12\n",
      "images shape: (32, 28, 28, 1)\n",
      "labels shape: (32,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-a9aa55300ad3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-d1d150d704fb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'labels shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {} finished'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-1c9e3c8e0c59>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(images, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# Add asserts to check the shape of the output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \"\"\"\n\u001b[1;32m--> 424\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m     name=None):\n\u001b[1;32m-> 1013\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1144\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2595\u001b[0m     \u001b[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2596\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2597\u001b[1;33m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m   2598\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2599\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    922\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    925\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 16) dtype=float32, numpy=\n",
       " array([[[[-0.12154196,  0.19620886,  0.18602411,  0.18985493,\n",
       "            0.1657337 ,  0.04148731, -0.13020304,  0.0029327 ,\n",
       "           -0.15226436,  0.13155273, -0.01044366, -0.10070579,\n",
       "           -0.09122629,  0.08013799,  0.04476796, -0.1932644 ]],\n",
       " \n",
       "         [[-0.03316274, -0.09844884, -0.16664006,  0.06727233,\n",
       "           -0.09404676,  0.01180836,  0.02455634,  0.06113025,\n",
       "            0.11195737,  0.09963435,  0.08064803,  0.06413048,\n",
       "            0.06695274, -0.15132248, -0.16455029, -0.10465654]],\n",
       " \n",
       "         [[ 0.14412752,  0.07732762,  0.06569345,  0.19844998,\n",
       "           -0.12001146, -0.16437156, -0.09148487,  0.01086803,\n",
       "           -0.16690923,  0.196875  , -0.08159024, -0.15596008,\n",
       "            0.11447214,  0.01506476, -0.07891957,  0.08591003]]],\n",
       " \n",
       " \n",
       "        [[[-0.04826206,  0.03478168, -0.15719701,  0.07471006,\n",
       "           -0.18633577,  0.09310967, -0.02222473, -0.18526702,\n",
       "            0.03303456, -0.09730665,  0.02749388,  0.12589534,\n",
       "           -0.02095336, -0.11695903, -0.15395942,  0.01914914]],\n",
       " \n",
       "         [[-0.12285616,  0.06109636, -0.1463984 ,  0.10272896,\n",
       "            0.1464495 , -0.05154099,  0.02874261,  0.13884443,\n",
       "           -0.03510179,  0.00905362,  0.19165742, -0.02537976,\n",
       "           -0.04749007,  0.01876752, -0.01160123,  0.14668527]],\n",
       " \n",
       "         [[ 0.01359564,  0.01551333,  0.016538  , -0.11693558,\n",
       "            0.08659941, -0.04062779, -0.16034447,  0.00038785,\n",
       "           -0.04092313,  0.03748204, -0.12053114,  0.15885104,\n",
       "            0.06814767, -0.02169842,  0.1889061 ,  0.01995266]]],\n",
       " \n",
       " \n",
       "        [[[ 0.19013111, -0.10662665,  0.02729668,  0.13306664,\n",
       "           -0.12350415, -0.01547521, -0.03087891, -0.12077448,\n",
       "            0.0573841 , -0.14294127,  0.21262428, -0.01129098,\n",
       "            0.16774695,  0.08158942,  0.19127508, -0.09672139]],\n",
       " \n",
       "         [[ 0.01953756, -0.08674634, -0.1910019 , -0.15514544,\n",
       "           -0.07507928, -0.04440015, -0.05907512,  0.09943581,\n",
       "            0.06280287, -0.14267883,  0.1981147 , -0.167969  ,\n",
       "           -0.15993851, -0.03877003, -0.06035861,  0.05867438]],\n",
       " \n",
       "         [[-0.12814522,  0.19808415,  0.00716058, -0.16600926,\n",
       "           -0.08825586, -0.08252555,  0.02593439, -0.02566199,\n",
       "            0.1471494 , -0.14521962, -0.09493292, -0.14278862,\n",
       "           -0.16148272, -0.14130454,  0.09549022, -0.12485596]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([ 1.4169549e-03, -2.8481008e-06,  1.1512295e-03, -6.5485307e-04,\n",
       "         2.2335217e-04,  1.2911884e-02,  1.5033852e-02, -6.7394227e-03,\n",
       "         8.0913759e-04, -5.5618928e-04,  6.4547434e-03,  1.9148220e-03,\n",
       "        -2.9734895e-03, -1.6701104e-03, -3.6181917e-03, -6.4722528e-03],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 16, 16) dtype=float32, numpy=\n",
       " array([[[[-0.1064925 ,  0.03319144,  0.12454784, ...,  0.06360384,\n",
       "           -0.09668099,  0.01319193],\n",
       "          [ 0.04344595,  0.08692161,  0.12070763, ..., -0.00974792,\n",
       "           -0.04537932,  0.03539633],\n",
       "          [ 0.09010347,  0.0804936 ,  0.05345522, ...,  0.14609331,\n",
       "           -0.12023807,  0.10039285],\n",
       "          ...,\n",
       "          [ 0.00963142,  0.08424892, -0.01730863, ...,  0.07186324,\n",
       "           -0.0261643 , -0.00394564],\n",
       "          [ 0.07759155,  0.04380341, -0.00478665, ..., -0.03311266,\n",
       "            0.16191125,  0.11961304],\n",
       "          [ 0.05258406,  0.04195462,  0.00497532, ...,  0.15540983,\n",
       "            0.10379444,  0.05499471]],\n",
       " \n",
       "         [[-0.00841841, -0.01391177, -0.10654598, ..., -0.03291938,\n",
       "            0.01895528,  0.0147425 ],\n",
       "          [ 0.06740543,  0.0946364 , -0.11852287, ...,  0.02666955,\n",
       "            0.03864767, -0.05589079],\n",
       "          [ 0.13648517,  0.0508047 , -0.02389685, ..., -0.00366178,\n",
       "           -0.07376295, -0.01078595],\n",
       "          ...,\n",
       "          [-0.0930263 , -0.10844243,  0.06273182, ...,  0.04283932,\n",
       "           -0.06284663,  0.13549624],\n",
       "          [ 0.00680864, -0.00716507, -0.00223984, ...,  0.00914078,\n",
       "            0.0359913 ,  0.01780893],\n",
       "          [-0.03931673, -0.06546491, -0.12284274, ..., -0.0079161 ,\n",
       "            0.0579402 ,  0.06985754]],\n",
       " \n",
       "         [[-0.01749099,  0.04397404,  0.03560595, ...,  0.03508138,\n",
       "           -0.11494055,  0.10625523],\n",
       "          [-0.01814179, -0.05413258, -0.03377163, ..., -0.06306296,\n",
       "            0.09993345, -0.07073442],\n",
       "          [-0.0124914 , -0.00436505, -0.05549099, ..., -0.12900464,\n",
       "            0.05696165, -0.04535429],\n",
       "          ...,\n",
       "          [ 0.09677354, -0.06631412, -0.09003266, ...,  0.03843325,\n",
       "           -0.08813643, -0.01847181],\n",
       "          [-0.00133648, -0.00087917,  0.11046658, ..., -0.03112182,\n",
       "           -0.07218868, -0.00552219],\n",
       "          [-0.09706376,  0.02338821, -0.12857221, ...,  0.09995394,\n",
       "           -0.0889156 ,  0.08607167]]],\n",
       " \n",
       " \n",
       "        [[[ 0.09372391,  0.13082425, -0.05455533, ..., -0.05241853,\n",
       "            0.01456781,  0.12984724],\n",
       "          [ 0.03522771, -0.03183451,  0.14087182, ..., -0.06317089,\n",
       "            0.05322628,  0.09871816],\n",
       "          [ 0.03401694,  0.00479202, -0.07739901, ...,  0.10658   ,\n",
       "            0.06525212,  0.09048106],\n",
       "          ...,\n",
       "          [ 0.12145755, -0.01850019,  0.1350729 , ...,  0.15459357,\n",
       "           -0.03522305,  0.02048291],\n",
       "          [-0.05222939, -0.05370463,  0.00370032, ...,  0.09599605,\n",
       "            0.06400529, -0.09203825],\n",
       "          [ 0.00326043,  0.00916622, -0.05139458, ..., -0.08006762,\n",
       "            0.01595246,  0.08917417]],\n",
       " \n",
       "         [[ 0.1482822 ,  0.14978242, -0.115096  , ..., -0.08596157,\n",
       "            0.04198349,  0.13332966],\n",
       "          [-0.04850644,  0.09551829, -0.01236665, ..., -0.09395531,\n",
       "           -0.0867208 ,  0.06647319],\n",
       "          [ 0.10247943, -0.09260829, -0.06263912, ...,  0.01012512,\n",
       "            0.0310415 ,  0.00927557],\n",
       "          ...,\n",
       "          [-0.09451806,  0.03488416,  0.13093045, ...,  0.07354546,\n",
       "            0.06429607,  0.03525484],\n",
       "          [ 0.09366284, -0.0176557 ,  0.12873687, ..., -0.13916677,\n",
       "           -0.00104628, -0.08845446],\n",
       "          [-0.03353038,  0.13746351, -0.03070255, ...,  0.08708221,\n",
       "           -0.01812733,  0.04186636]],\n",
       " \n",
       "         [[ 0.00609205,  0.09651737, -0.0615475 , ...,  0.09116268,\n",
       "           -0.00871486,  0.09471665],\n",
       "          [ 0.05589713,  0.10468839,  0.05206051, ..., -0.0434128 ,\n",
       "            0.03027497,  0.11997362],\n",
       "          [ 0.00018623, -0.14547618,  0.06625701, ...,  0.01040739,\n",
       "           -0.01563393, -0.01340582],\n",
       "          ...,\n",
       "          [ 0.08228111,  0.12224134, -0.13831683, ...,  0.14247261,\n",
       "            0.1377865 ,  0.10601405],\n",
       "          [ 0.01218717,  0.02850215,  0.01458513, ...,  0.10554721,\n",
       "            0.00022235, -0.13312298],\n",
       "          [ 0.00449511, -0.03554364, -0.01093085, ..., -0.0360539 ,\n",
       "           -0.10457332,  0.01442375]]],\n",
       " \n",
       " \n",
       "        [[[-0.08346181,  0.16099468, -0.09124291, ..., -0.09158989,\n",
       "            0.11795029, -0.0776182 ],\n",
       "          [-0.00042449, -0.02144252,  0.08040272, ..., -0.06658242,\n",
       "            0.09183404, -0.08319275],\n",
       "          [-0.0984693 , -0.08086446,  0.05217168, ..., -0.04579409,\n",
       "           -0.09223159,  0.11774943],\n",
       "          ...,\n",
       "          [-0.0704592 , -0.03059646,  0.06229861, ...,  0.14625952,\n",
       "            0.08052044, -0.13369277],\n",
       "          [ 0.14890534, -0.07815272,  0.13777924, ..., -0.0166021 ,\n",
       "            0.14316869, -0.10030703],\n",
       "          [ 0.1219796 ,  0.0089968 ,  0.07025088, ...,  0.08162945,\n",
       "           -0.08455496, -0.13490245]],\n",
       " \n",
       "         [[ 0.12676246, -0.0441044 ,  0.05381943, ..., -0.10632606,\n",
       "            0.11300328,  0.02836644],\n",
       "          [-0.07408625,  0.12647298,  0.10702346, ..., -0.10142378,\n",
       "           -0.04928117, -0.13861677],\n",
       "          [-0.08231938,  0.03423451,  0.00258217, ...,  0.01646893,\n",
       "            0.13476501, -0.09764345],\n",
       "          ...,\n",
       "          [ 0.08775026, -0.03024455,  0.0697984 , ...,  0.03319403,\n",
       "           -0.081456  ,  0.05149208],\n",
       "          [-0.01586456,  0.01287922,  0.15424465, ...,  0.07172599,\n",
       "           -0.10377344,  0.09495908],\n",
       "          [-0.05399784, -0.11413518,  0.00660417, ..., -0.04751705,\n",
       "            0.05876606,  0.11542732]],\n",
       " \n",
       "         [[ 0.07401963,  0.01715071,  0.09302485, ..., -0.1294886 ,\n",
       "            0.08547802,  0.05013578],\n",
       "          [ 0.04721029, -0.00383337, -0.00112399, ..., -0.14534287,\n",
       "           -0.00116936, -0.05972672],\n",
       "          [-0.12479294, -0.03608655,  0.10216422, ..., -0.10418614,\n",
       "           -0.09888925, -0.14812942],\n",
       "          ...,\n",
       "          [ 0.05348145, -0.00353181, -0.1539634 , ...,  0.1084876 ,\n",
       "           -0.0969405 ,  0.00561499],\n",
       "          [ 0.00164879, -0.02599009,  0.06502437, ..., -0.04883567,\n",
       "           -0.02584897,  0.05542542],\n",
       "          [-0.0552738 , -0.02969775, -0.05965822, ...,  0.13512549,\n",
       "            0.05420232, -0.07697535]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_1/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([ 0.00185936, -0.00704963,  0.00469797, -0.00706123, -0.00236005,\n",
       "         0.00032853, -0.00047629,  0.00073041, -0.00042644, -0.00876502,\n",
       "        -0.00971931, -0.00680874,  0.00710753,  0.02972651,  0.00356445,\n",
       "        -0.00847986], dtype=float32)>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(16, 10) dtype=float32, numpy=\n",
       " array([[ 0.3844797 , -0.3492624 , -0.0196367 , -0.08786529,  0.00072269,\n",
       "          0.43453902, -0.36142814, -0.09539475,  0.2421547 ,  0.14531524],\n",
       "        [ 0.3079161 , -0.3561038 , -0.45126823,  0.43036163, -0.3843281 ,\n",
       "         -0.44570076, -0.41608876, -0.4422426 ,  0.24530265,  0.07842515],\n",
       "        [ 0.06309003, -0.3631265 ,  0.18045095, -0.20116666, -0.3863829 ,\n",
       "         -0.01400795,  0.3944683 ,  0.35515225, -0.2342809 , -0.01809944],\n",
       "        [ 0.07520004, -0.08885223, -0.08952817,  0.33133468, -0.477945  ,\n",
       "         -0.23832236,  0.4223023 , -0.02870964,  0.0297447 , -0.15278289],\n",
       "        [-0.27781817, -0.12556362,  0.19599408,  0.29428542, -0.26805806,\n",
       "         -0.26276633,  0.06312215,  0.08163416, -0.17699978,  0.00972248],\n",
       "        [-0.14599523, -0.4854227 ,  0.38624924,  0.29051587,  0.35708374,\n",
       "         -0.1986549 ,  0.03911692, -0.08502503,  0.28496712, -0.45135063],\n",
       "        [ 0.14737408, -0.3331649 , -0.34990987, -0.00909909, -0.45293316,\n",
       "         -0.01806526, -0.25204667, -0.13051865, -0.16011487, -0.2646532 ],\n",
       "        [-0.37441638, -0.28458667, -0.3287926 ,  0.2913306 ,  0.1422439 ,\n",
       "          0.05365876, -0.2167433 , -0.04810923, -0.40861478,  0.3072929 ],\n",
       "        [-0.34192938,  0.25291306,  0.18385933, -0.18672422,  0.08171535,\n",
       "          0.3125417 , -0.29135728, -0.3853955 ,  0.34101245, -0.47113594],\n",
       "        [ 0.38922405,  0.08444232,  0.17093681, -0.42329913, -0.30598608,\n",
       "         -0.18256502,  0.32810935, -0.37923297, -0.01584475,  0.39841357],\n",
       "        [ 0.23597936,  0.02847898, -0.11280473,  0.08346932, -0.1810855 ,\n",
       "         -0.43968058, -0.39141858, -0.1279104 ,  0.2122212 ,  0.4415937 ],\n",
       "        [ 0.16399047, -0.06560934, -0.346558  ,  0.16110952,  0.438517  ,\n",
       "          0.39683297,  0.37604505, -0.47754055, -0.01051935,  0.2170282 ],\n",
       "        [ 0.15867375, -0.2738567 ,  0.02723963, -0.08614131,  0.22009769,\n",
       "          0.3201894 ,  0.31527412,  0.42979208, -0.28038442, -0.01479569],\n",
       "        [-0.07288861,  0.41338223,  0.04808887, -0.42115545, -0.05582563,\n",
       "          0.29653835, -0.21774025,  0.07583281,  0.2789057 ,  0.13090643],\n",
       "        [ 0.4614363 , -0.3206783 ,  0.1077138 ,  0.4490879 , -0.08482519,\n",
       "          0.27171242,  0.30380937,  0.2968629 ,  0.05873185, -0.29161847],\n",
       "        [-0.02629539,  0.2042517 ,  0.292364  ,  0.4440445 , -0.3618075 ,\n",
       "         -0.33413666, -0.031953  , -0.24963923,  0.37584543,  0.14515702]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.01304472,  0.02186419, -0.01087044, -0.01008646,  0.00572259,\n",
       "        -0.00494927, -0.01008879,  0.01525143, -0.00581007, -0.01094587],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss [entropy]')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Loss [entropy]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Linear, self).__init__()\n",
    "    self.W = tf.Variable(5., name='weight')\n",
    "    self.B = tf.Variable(10., name='bias')\n",
    "  def call(self, inputs):\n",
    "    return inputs * self.W + self.B\n",
    "\n",
    "# A toy dataset of points around 3 * x + 2\n",
    "NUM_EXAMPLES = 2000\n",
    "training_inputs = tf.random.normal([NUM_EXAMPLES])\n",
    "noise = tf.random.normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "\n",
    "# The loss function to be optimized\n",
    "def loss(model, inputs, targets):\n",
    "  error = model(inputs) - targets\n",
    "  return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, [model.W, model.B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(checkpoint_dir):\n",
    "  os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT!\n",
    "# https://medium.com/analytics-vidhya/tf-gradienttape-explained-for-keras-users-cc3f06276f22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/analytics-vidhya/implementing-adversarial-attacks-and-defenses-in-keras-tensorflow-2-0-cab6120c5715\n",
    "    \n",
    "https://medium.com/analytics-vidhya/transforming-the-world-into-paintings-with-cyclegan-6748c0b85632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    result = add(2*v, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading model problems (keeping optimizer state)\n",
    "# How to resume training (finetuning) keeping the optimizer state!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) DO NOT load_weights() after defining model again!\n",
    "    Redefining the model followed by load_weight() definitely won't work, because save_weight() and load_weight() does not save/load the optimizer! \n",
    "    \n",
    "https://stackoverflow.com/questions/47995324/does-model-compile-initialize-all-the-weights-and-biases-in-keras-tensorflow#:~:text=Compile%20defines%20the%20loss%20function,loss%20function%20and%20the%20optimizer\n",
    "    \n",
    "### 2) DO NOT compile model after load_model()\n",
    "    Did you call model.compile(optimizer='adam') after load_model()? If so, don't do that. Re-compiling the model with the option optimizer='adam' will reset the inner state of the optimizer (in fact, a new Adam optimizer instance is created)\n",
    "    Just call load_model() followed by model.fit()\n",
    "\n",
    "https://stackoverflow.com/questions/45393429/keras-how-to-save-model-and-continue-training?noredirect=1&lq=1\n",
    "\n",
    "#### THE PREVIOUS LINK MIGHT HAVE FULLY WORKING EXAMPLE!!\n",
    "\n",
    "    \n",
    "### 3) Be carefull with the learning rate on plateau! \n",
    "      reduce_lr = ReduceLROnPlateau(monitor='loss', factor=lr_reduction_factor,\n",
    "                              patience=patience, min_lr=min_lr, verbose=1)\n",
    "https://stackoverflow.com/questions/42666046/loading-a-trained-keras-model-and-continue-training?rq=1 \n",
    "\n",
    "#### THE PREVIOUS LINK MIGHT HAVE FULLY WORKING EXAMPLE IN SUBLINKS!!\n",
    "\n",
    "\n",
    "### 4)Please save the model in *.tf format. From my experience, if you have any custom_loss defined, *.h5 format will not save optimizer status and hence will not serve your purpose if you want to retrain the model from where we left.\n",
    "\n",
    "https://stackoverflow.com/questions/42666046/loading-a-trained-keras-model-and-continue-training?rq=1\n",
    "\n",
    "### 5) Save and load optimizer state\n",
    "https://stackoverflow.com/questions/49503748/save-and-load-model-optimizer-state\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### 6) see https://www.tensorflow.org/guide/eager for saving optimizer state with CheckPoints!!\n",
    "\n",
    "### 7) \n",
    "\n",
    "#### Does model.save() and load_model() work alone without anything else to load the state of the optimizer???\n",
    "\n",
    "https://stackoverflow.com/questions/56414605/keras-how-to-resume-training-with-adam-optimizer\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "https://stackoverflow.com/questions/48161147/error-restoring-model-in-tensorflow-after-changing-the-optimizer-paramter/48212514#48212514\n",
    "\n",
    "**Is this true???** <br>\n",
    "https://github.com/keras-team/keras/issues/2378\n",
    "\n",
    "It is happening because model.save(filename.h5) does not save the state of the optimizer. So the optimizers like Adam, RMSProp does not work but SGD works as mentioned in one of the previous comments (I verified this) since it is stateless optimizer (learning rate is fixed).\n",
    "\n",
    "This is just sad that such a popular library has such basic/glaring/trivial bugs/problems :(\n",
    "\n",
    "**MAYBE NOT** chollet says: \"Yes. The optimizer state isn't reset until you recompile the model with a new optimizer.\" in the https://github.com/keras-team/keras/issues/3704#issuecomment-245052225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - We may have problems resuming and keeping optimizer state in tensorflow work in Fujitsu!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Keras Questions\n",
    "- https://keras.io/getting_started/faq/#how-can-i-save-a-keras-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tricks in training NNs:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources to see:\n",
    "- https://stackoverflow.com/questions/45393429/keras-how-to-save-model-and-continue-training?noredirect=1&lq=1\n",
    "- https://stackoverflow.com/questions/42666046/loading-a-trained-keras-model-and-continue-training?rq=1\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
