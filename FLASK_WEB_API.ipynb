{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn  a machine learning model into web API\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/machine-learning-models-api-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\30694\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\30694\\anaconda3\\lib\\site-packages (from flask) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\30694\\anaconda3\\lib\\site-packages (from flask) (1.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\30694\\anaconda3\\lib\\site-packages (from flask) (2.11.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\30694\\anaconda3\\lib\\site-packages (from flask) (7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\30694\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask  #automatically comes with Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!!RUN IT IN SEPARATE SCRIPT!!!\n",
    "\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"My first web API\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)  #,port = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You created an instance of the Flask class and passed in the \"name\" variable (which is filled by Python itself). This variable will be \"main\", if this file is being directly run through Python as a script. If you imported the file instead, the value of \"name\" would be the name of the file which you imported. For example, if you had test.py and run.py, and you imported test.py into run.py the \"name\" value of test.py will be test (app = Flask(test))\n",
    "\n",
    "### Search for\n",
    "### machine-learning-models-api-python.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train with Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         1\n",
       "2  26.0  female        S         1\n",
       "3  35.0  female        S         1\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset in a dataframe object and include only four features as mentioned\n",
    "url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "df = pd.read_csv(url)\n",
    "include = ['Age', 'Sex', 'Embarked', 'Survived'] # Only four features\n",
    "df_ = df[include]\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age float64\n",
      "-----------\n",
      "Sex object\n",
      "OBJECT TYPE\n",
      " \"O\" col_type: Sex\n",
      "-----------\n",
      "Embarked object\n",
      "OBJECT TYPE\n",
      " \"O\" col_type: Embarked\n",
      "-----------\n",
      "Survived int64\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for col, col_type in df_.dtypes.iteritems():\n",
    "    print(col, col_type)\n",
    "    if col_type == object:\n",
    "        print('OBJECT TYPE')\n",
    "    if col_type == 'O':\n",
    "        print(' \"O\" col_type:', col)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30694\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "categoricals = []\n",
    "for col, col_type in df_.dtypes.iteritems():\n",
    "     if col_type == 'O':\n",
    "          categoricals.append(col)\n",
    "     else:\n",
    "          df_[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df_, columns=categoricals, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "dependent_variable = 'Survived'\n",
    "x = df_ohe[df_ohe.columns.difference([dependent_variable])]\n",
    "y = df_ohe[dependent_variable]\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30694\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['log_reg_model_titanic.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#joblib.dump(lr, 'log_reg_model_titanic.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('log_reg_model_titanic.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f , protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S',\n",
       " 'Embarked_nan',\n",
       " 'Sex_female',\n",
       " 'Sex_male',\n",
       " 'Sex_nan']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_columns = list(x.columns)\n",
    "model_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models columns dumped!\n"
     ]
    }
   ],
   "source": [
    "# Saving the data columns from training  (dont't understand this...)\n",
    "with open('log_reg_model_titanic_columns.pkl', 'wb') as f:\n",
    "    pickle.dump(model_columns, f , protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Models columns dumped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
